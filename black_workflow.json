{
  "3": {
    "inputs": {
      "seed": 916789955313112,
      "steps": 20,
      "cfg": 7.0,
      "sampler_name": "dpmpp_sde",
      "scheduler": "karras",
      "denoise": 0.5,
      "model": [
        "36",
        0
      ],
      "positive": [
        "41",
        0
      ],
      "negative": [
        "41",
        1
      ],
      "latent_image": [
        "41",
        3
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "4": {
    "inputs": {
      "ckpt_name": "realvisxlV40_v40LightningBakedvae.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "6": {
    "inputs": {
      "text": "High Resolution, (skin texture:1.2), natural skin, clear skin",
      "clip": [
        "4",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "7": {
    "inputs": {
      "text": "(tattoos:1.4), blurry, low resolution, text, digital, cgi, deformed, 3D, (worst quality, low quality, illustration, 3d, 2d, painting, cartoons, sketch)",
      "clip": [
        "4",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "8": {
    "inputs": {
      "samples": [
        "3",
        0
      ],
      "vae": [
        "4",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "11": {
    "inputs": {
      "image": "clipspace/clipspace-mask-14328800.png [input]",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "13": {
    "inputs": {
      "expand": 2,
      "tapered_corners": true,
      "mask": [
        "55",
        0
      ]
    },
    "class_type": "GrowMask",
    "_meta": {
      "title": "GrowMask"
    }
  },
  "32": {
    "inputs": {
      "scale": 0.5,
      "blur_sigma": 2,
      "model": [
        "4",
        0
      ]
    },
    "class_type": "SelfAttentionGuidance",
    "_meta": {
      "title": "Self-Attention Guidance"
    }
  },
  "33": {
    "inputs": {
      "model": [
        "32",
        0
      ]
    },
    "class_type": "DifferentialDiffusion",
    "_meta": {
      "title": "Differential Diffusion"
    }
  },
  "36": {
    "inputs": {
      "model": [
        "33",
        0
      ],
      "patch": [
        "37",
        0
      ],
      "latent": [
        "41",
        2
      ]
    },
    "class_type": "INPAINT_ApplyFooocusInpaint",
    "_meta": {
      "title": "Apply Fooocus Inpaint"
    }
  },
  "37": {
    "inputs": {
      "head": "fooocus_inpaint_head.pth",
      "patch": "inpaint_v26.fooocus.patch"
    },
    "class_type": "INPAINT_LoadFooocusInpaint",
    "_meta": {
      "title": "Load Fooocus Inpaint"
    }
  },
  "41": {
    "inputs": {
      "positive": [
        "6",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "vae": [
        "4",
        2
      ],
      "pixels": [
        "11",
        0
      ],
      "mask": [
        "46",
        0
      ]
    },
    "class_type": "INPAINT_VAEEncodeInpaintConditioning",
    "_meta": {
      "title": "VAE Encode & Inpaint Conditioning"
    }
  },
  "46": {
    "inputs": {
      "kernel_size": 10,
      "sigma": 10,
      "mask": [
        "13",
        0
      ]
    },
    "class_type": "ImpactGaussianBlurMask",
    "_meta": {
      "title": "Gaussian Blur Mask"
    }
  },
  "47": {
    "inputs": {
      "x": 0,
      "y": 0,
      "resize_source": true,
      "destination": [
        "11",
        0
      ],
      "source": [
        "8",
        0
      ],
      "mask": [
        "46",
        0
      ]
    },
    "class_type": "ImageCompositeMasked",
    "_meta": {
      "title": "ImageCompositeMasked"
    }
  },
  "52": {
    "inputs": {
      "filename_prefix": "image",
      "images": [
        "47",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "54": {
    "inputs": {
      "image": "181204-F-ED851-0005.webp",
      "channel": "alpha",
      "upload": "image"
    },
    "class_type": "LoadImageMask",
    "_meta": {
      "title": "Load Image (as Mask)"
    }
  },
  "55": {
    "inputs": {
      "mask": [
        "54",
        0
      ]
    },
    "class_type": "InvertMask",
    "_meta": {
      "title": "InvertMask"
    }
  }
}